{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>question</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>electronics</td>\n",
       "      <td>What is the effective differencial effective o...</td>\n",
       "      <td>I'm trying to work out, in general terms, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>electronics</td>\n",
       "      <td>Heat sensor with fan cooling</td>\n",
       "      <td>Can I know which component senses heat or acts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>electronics</td>\n",
       "      <td>Outlet Installation--more wires than my new ou...</td>\n",
       "      <td>I am replacing a wall outlet with a Cooper Wir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electronics</td>\n",
       "      <td>Buck Converter Operation Question</td>\n",
       "      <td>i have been reading about the buck converter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electronics</td>\n",
       "      <td>Urgent help in area of ASIC design, verificati...</td>\n",
       "      <td>I need help with deciding on a Master's Projec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20214</th>\n",
       "      <td>wordpress</td>\n",
       "      <td>How to set a Custom Post Type as the parent of...</td>\n",
       "      <td>I have a Custom Post Type called Recipe with p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20215</th>\n",
       "      <td>wordpress</td>\n",
       "      <td>Tracking last login and last visit</td>\n",
       "      <td>I'm using the code below to track when a user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216</th>\n",
       "      <td>wordpress</td>\n",
       "      <td>How to exclude the particular category from th...</td>\n",
       "      <td>add_action( 'pre_get_posts', 'custom_pre_get_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20217</th>\n",
       "      <td>wordpress</td>\n",
       "      <td>display sub categories assoccited with each po...</td>\n",
       "      <td>i have wordpress blog with many posts. each po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20218</th>\n",
       "      <td>wordpress</td>\n",
       "      <td>Lost of query parameter when using permalink</td>\n",
       "      <td>I have many issues with the use of rewriting, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic                                           question  \\\n",
       "0      electronics  What is the effective differencial effective o...   \n",
       "1      electronics                       Heat sensor with fan cooling   \n",
       "2      electronics  Outlet Installation--more wires than my new ou...   \n",
       "3      electronics                  Buck Converter Operation Question   \n",
       "4      electronics  Urgent help in area of ASIC design, verificati...   \n",
       "...            ...                                                ...   \n",
       "20214    wordpress  How to set a Custom Post Type as the parent of...   \n",
       "20215    wordpress                 Tracking last login and last visit   \n",
       "20216    wordpress  How to exclude the particular category from th...   \n",
       "20217    wordpress  display sub categories assoccited with each po...   \n",
       "20218    wordpress       Lost of query parameter when using permalink   \n",
       "\n",
       "                                                 excerpt  \n",
       "0      I'm trying to work out, in general terms, the ...  \n",
       "1      Can I know which component senses heat or acts...  \n",
       "2      I am replacing a wall outlet with a Cooper Wir...  \n",
       "3      i have been reading about the buck converter, ...  \n",
       "4      I need help with deciding on a Master's Projec...  \n",
       "...                                                  ...  \n",
       "20214  I have a Custom Post Type called Recipe with p...  \n",
       "20215  I'm using the code below to track when a user ...  \n",
       "20216  add_action( 'pre_get_posts', 'custom_pre_get_p...  \n",
       "20217  i have wordpress blog with many posts. each po...  \n",
       "20218  I have many issues with the use of rewriting, ...  \n",
       "\n",
       "[20219 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    data = data.strip().split('\\n')\n",
    "\n",
    "    dataset = []\n",
    "    for i in data:\n",
    "        try:\n",
    "            dataset.append(json.loads(i))\n",
    "        except:\n",
    "            print(i)\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "\n",
    "    return df\n",
    "\n",
    "TRAIN = load_data('data/train/train.json')\n",
    "TRAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['topic', 'question', 'excerpt'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Function to clean text and perform lemitisation\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = TRAIN.copy()\n",
    "df['text'] = df['question'] + \" \" + df['excerpt']\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "df = df[['text', 'topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'effective differencial effective circuit im trying work general term effective capacitance circuit see diagram httpistackimgurcombs85bpng effective capacitance circuit'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer Methord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def vectorirse_text(text):\n",
    "    \"\"\" Recieves text as input and returns TF-IDF vectors\"\"\"\n",
    "    tfidf = TfidfVectorizer(max_features=500000)\n",
    "    X = tfidf.fit_transform(text)\n",
    "    return X\n",
    "\n",
    "def label_encoding(input):\n",
    "    label_encoder = LabelEncoder()\n",
    "    return label_encoder.fit_transform(input)\n",
    "\n",
    "\n",
    "X = vectorirse_text(df['text'])\n",
    "y = label_encoding(df['topic'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multi-Layer Perceptron (MLP - Neural Network):\n",
      "Accuracy: 0.7925321463897131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       458\n",
      "           1       0.61      0.72      0.66       396\n",
      "           2       0.91      0.80      0.85       363\n",
      "           3       0.75      0.92      0.83       497\n",
      "           4       0.73      0.74      0.73       294\n",
      "           5       0.83      0.84      0.84       368\n",
      "           6       0.99      0.82      0.89       498\n",
      "           7       0.74      0.78      0.76       388\n",
      "           8       0.73      0.66      0.69       396\n",
      "           9       0.90      0.83      0.86       386\n",
      "\n",
      "    accuracy                           0.79      4044\n",
      "   macro avg       0.80      0.79      0.79      4044\n",
      "weighted avg       0.80      0.79      0.79      4044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "print(\"Logistic Regression:\")\n",
    "report, acc = logistic_regression(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "report, acc = decision_tree(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "report, acc = random_forest(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nSupport Vector Machine (SVM):\")\n",
    "report, acc = support_vector_machine(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nk-Nearest Neighbors (k-NN):\")\n",
    "report, acc = knn(X, y, k=5)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nNaïve Bayes Classifier:\")\n",
    "report, acc = naive_bayes(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nGradient Boosting (XGBoost):\")\n",
    "report, acc = xgboost_classifier(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nMulti-Layer Perceptron (MLP - Neural Network):\")\n",
    "report, acc = mlp_classifier(X, y)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vector Methord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df['tokens'] = df['text'].apply(lambda x: x.split())\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(sentences=df['tokens'], vector_size=10000, window=5, min_count=2, workers=10)\n",
    "\n",
    "def get_sentence_embedding(tokens):\n",
    "    vectors = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "X_w2v = np.array(df['tokens'].apply(get_sentence_embedding).tolist())\n",
    "y_encoded = label_encoding(df['topic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_w2v\n",
    "y = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6434223541048467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       458\n",
      "           1       0.52      0.48      0.50       396\n",
      "           2       0.56      0.68      0.61       363\n",
      "           3       0.68      0.69      0.69       497\n",
      "           4       0.56      0.53      0.55       294\n",
      "           5       0.73      0.75      0.74       368\n",
      "           6       0.70      0.79      0.74       498\n",
      "           7       0.57      0.49      0.53       388\n",
      "           8       0.50      0.48      0.49       396\n",
      "           9       0.76      0.70      0.73       386\n",
      "\n",
      "    accuracy                           0.64      4044\n",
      "   macro avg       0.64      0.63      0.63      4044\n",
      "weighted avg       0.64      0.64      0.64      4044\n",
      "\n",
      "\n",
      "Decision Tree Classifier:\n",
      "Accuracy: 0.5054401582591493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       458\n",
      "           1       0.37      0.39      0.38       396\n",
      "           2       0.44      0.49      0.46       363\n",
      "           3       0.54      0.51      0.52       497\n",
      "           4       0.34      0.33      0.34       294\n",
      "           5       0.60      0.68      0.64       368\n",
      "           6       0.73      0.65      0.69       498\n",
      "           7       0.37      0.34      0.36       388\n",
      "           8       0.31      0.33      0.32       396\n",
      "           9       0.58      0.62      0.60       386\n",
      "\n",
      "    accuracy                           0.51      4044\n",
      "   macro avg       0.50      0.50      0.50      4044\n",
      "weighted avg       0.51      0.51      0.51      4044\n",
      "\n",
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 0.6271018793273986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       458\n",
      "           1       0.48      0.49      0.49       396\n",
      "           2       0.52      0.62      0.56       363\n",
      "           3       0.62      0.66      0.64       497\n",
      "           4       0.53      0.51      0.52       294\n",
      "           5       0.77      0.77      0.77       368\n",
      "           6       0.79      0.78      0.78       498\n",
      "           7       0.57      0.45      0.50       388\n",
      "           8       0.47      0.50      0.49       396\n",
      "           9       0.70      0.67      0.69       386\n",
      "\n",
      "    accuracy                           0.63      4044\n",
      "   macro avg       0.62      0.62      0.62      4044\n",
      "weighted avg       0.63      0.63      0.63      4044\n",
      "\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "[LibSVM]*.*\n",
      "optimization finished, #iter = 1036\n",
      "obj = -1517.315510, rho = -1.694230\n",
      "nSV = 1625, nBSV = 1606\n",
      "Total nSV = 1625\n",
      "*\n",
      "optimization finished, #iter = 982\n",
      "obj = -1479.052357, rho = -1.032787\n",
      "nSV = 1587, nBSV = 1574\n",
      "Total nSV = 1587\n",
      "*.*\n",
      "optimization finished, #iter = 1019\n",
      "obj = -1511.285642, rho = -1.209375\n",
      "nSV = 1618, nBSV = 1605\n",
      "Total nSV = 1618\n",
      "*.*\n",
      "optimization finished, #iter = 1038\n",
      "obj = -1524.714607, rho = -1.314464\n",
      "nSV = 1633, nBSV = 1616\n",
      "Total nSV = 1633\n",
      "*.*\n",
      "optimization finished, #iter = 1095\n",
      "obj = -1494.181777, rho = -0.849238\n",
      "nSV = 1600, nBSV = 1581\n",
      "Total nSV = 1600\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1290\n",
      "obj = -1858.225228, rho = 1.212579\n",
      "nSV = 1983, nBSV = 1964\n",
      "*\n",
      "optimization finished, #iter = 382\n",
      "obj = -490.424949, rho = -0.180521\n",
      "nSV = 572, nBSV = 561\n",
      "Total nSV = 572\n",
      "*\n",
      "optimization finished, #iter = 399\n",
      "obj = -491.822784, rho = -0.089091\n",
      "nSV = 576, nBSV = 564\n",
      "Total nSV = 576\n",
      "*\n",
      "optimization finished, #iter = 393\n",
      "obj = -474.182300, rho = 0.230688\n",
      "nSV = 557, nBSV = 546\n",
      "Total nSV = 557\n",
      "*\n",
      "optimization finished, #iter = 416\n",
      "obj = -505.775569, rho = 0.153069\n",
      "nSV = 588, nBSV = 575\n",
      "Total nSV = 588\n",
      "*\n",
      "optimization finished, #iter = 458\n",
      "obj = -498.473668, rho = 0.204678\n",
      "nSV = 581, nBSV = 567\n",
      "Total nSV = 581\n",
      "Line search fails in two-class probability estimates\n",
      "*\n",
      "optimization finished, #iter = 522\n",
      "obj = -596.023598, rho = -0.052335\n",
      "nSV = 691, nBSV = 676\n",
      "*\n",
      "optimization finished, #iter = 244\n",
      "obj = -319.875873, rho = -0.182741\n",
      "nSV = 367, nBSV = 360\n",
      "Total nSV = 367\n",
      "*\n",
      "optimization finished, #iter = 252\n",
      "obj = -323.460100, rho = -1.047336\n",
      "nSV = 371, nBSV = 364\n",
      "Total nSV = 371\n",
      "*\n",
      "optimization finished, #iter = 274\n",
      "obj = -326.774597, rho = -0.588755\n",
      "nSV = 377, nBSV = 366\n",
      "Total nSV = 377\n",
      "*\n",
      "optimization finished, #iter = 260\n",
      "obj = -330.207475, rho = -0.283656\n",
      "nSV = 379, nBSV = 370\n",
      "Total nSV = 379\n",
      "*\n",
      "optimization finished, #iter = 269\n",
      "obj = -307.486998, rho = -0.843473\n",
      "nSV = 359, nBSV = 349\n",
      "Total nSV = 359\n",
      "*\n",
      "optimization finished, #iter = 319\n",
      "obj = -391.805767, rho = 0.626391\n",
      "nSV = 449, nBSV = 436\n",
      "*\n",
      "optimization finished, #iter = 232\n",
      "obj = -269.133768, rho = -0.874751\n",
      "nSV = 319, nBSV = 310\n",
      "Total nSV = 319\n",
      "*\n",
      "optimization finished, #iter = 225\n",
      "obj = -269.519125, rho = -0.953848\n",
      "nSV = 320, nBSV = 312\n",
      "Total nSV = 320\n",
      "*\n",
      "optimization finished, #iter = 226\n",
      "obj = -267.347997, rho = -0.869605\n",
      "nSV = 317, nBSV = 309\n",
      "Total nSV = 317\n",
      "*\n",
      "optimization finished, #iter = 237\n",
      "obj = -267.065306, rho = -1.017752\n",
      "nSV = 317, nBSV = 307\n",
      "Total nSV = 317\n",
      "*\n",
      "optimization finished, #iter = 241\n",
      "obj = -268.581593, rho = -1.077961\n",
      "nSV = 319, nBSV = 308\n",
      "Total nSV = 319\n",
      "*\n",
      "optimization finished, #iter = 315\n",
      "obj = -324.261367, rho = 1.030535\n",
      "nSV = 382, nBSV = 371\n",
      "*\n",
      "optimization finished, #iter = 438\n",
      "obj = -574.864069, rho = 0.429757\n",
      "nSV = 659, nBSV = 648\n",
      "Total nSV = 659\n",
      "*\n",
      "optimization finished, #iter = 435\n",
      "obj = -567.882714, rho = 0.040911\n",
      "nSV = 655, nBSV = 644\n",
      "Total nSV = 655\n",
      "*\n",
      "optimization finished, #iter = 478\n",
      "obj = -580.675366, rho = 0.246804\n",
      "nSV = 668, nBSV = 656\n",
      "Total nSV = 668\n",
      "*\n",
      "optimization finished, #iter = 467\n",
      "obj = -574.076239, rho = 0.347992\n",
      "nSV = 666, nBSV = 652\n",
      "Total nSV = 666\n",
      "*\n",
      "optimization finished, #iter = 465\n",
      "obj = -580.355347, rho = 0.377928\n",
      "nSV = 666, nBSV = 656\n",
      "Total nSV = 666\n",
      "*\n",
      "optimization finished, #iter = 566\n",
      "obj = -699.220027, rho = -0.391056\n",
      "nSV = 798, nBSV = 785\n",
      "*\n",
      "optimization finished, #iter = 259\n",
      "obj = -316.467187, rho = 1.022385\n",
      "nSV = 388, nBSV = 380\n",
      "Total nSV = 388\n",
      "*\n",
      "optimization finished, #iter = 272\n",
      "obj = -328.430107, rho = 0.396892\n",
      "nSV = 401, nBSV = 389\n",
      "Total nSV = 401\n",
      "*\n",
      "optimization finished, #iter = 270\n",
      "obj = -314.593285, rho = 0.881492\n",
      "nSV = 389, nBSV = 380\n",
      "Total nSV = 389\n",
      "*\n",
      "optimization finished, #iter = 270\n",
      "obj = -327.279770, rho = 1.090755\n",
      "nSV = 400, nBSV = 393\n",
      "Total nSV = 400\n",
      "*\n",
      "optimization finished, #iter = 244\n",
      "obj = -328.086763, rho = 0.776954\n",
      "nSV = 401, nBSV = 392\n",
      "Total nSV = 401\n",
      "*\n",
      "optimization finished, #iter = 346\n",
      "obj = -386.703173, rho = -0.894051\n",
      "nSV = 469, nBSV = 457\n",
      "*\n",
      "optimization finished, #iter = 509\n",
      "obj = -640.814864, rho = 0.478834\n",
      "nSV = 730, nBSV = 717\n",
      "Total nSV = 730\n",
      "*\n",
      "optimization finished, #iter = 524\n",
      "obj = -630.628282, rho = -0.003386\n",
      "nSV = 716, nBSV = 699\n",
      "Total nSV = 716\n",
      "*\n",
      "optimization finished, #iter = 489\n",
      "obj = -630.190682, rho = 0.161799\n",
      "nSV = 714, nBSV = 703\n",
      "Total nSV = 714\n",
      "*\n",
      "optimization finished, #iter = 516\n",
      "obj = -652.129120, rho = 0.198138\n",
      "nSV = 741, nBSV = 727\n",
      "Total nSV = 741\n",
      "*\n",
      "optimization finished, #iter = 480\n",
      "obj = -627.104121, rho = 0.043070\n",
      "nSV = 712, nBSV = 702\n",
      "Total nSV = 712\n",
      "*\n",
      "optimization finished, #iter = 605\n",
      "obj = -774.908387, rho = -0.218843\n",
      "nSV = 876, nBSV = 863\n",
      "*\n",
      "optimization finished, #iter = 491\n",
      "obj = -662.461178, rho = 0.064231\n",
      "nSV = 745, nBSV = 731\n",
      "Total nSV = 745\n",
      "*\n",
      "optimization finished, #iter = 504\n",
      "obj = -661.785826, rho = 0.193410\n",
      "nSV = 744, nBSV = 729\n",
      "Total nSV = 744\n",
      "*\n",
      "optimization finished, #iter = 535\n",
      "obj = -667.479321, rho = 0.127282\n",
      "nSV = 748, nBSV = 736\n",
      "Total nSV = 748\n",
      "*\n",
      "optimization finished, #iter = 471\n",
      "obj = -665.825970, rho = 0.424384\n",
      "nSV = 748, nBSV = 736\n",
      "Total nSV = 748\n",
      "*\n",
      "optimization finished, #iter = 475\n",
      "obj = -677.242928, rho = 0.038673\n",
      "nSV = 759, nBSV = 749\n",
      "Total nSV = 759\n",
      "*\n",
      "optimization finished, #iter = 609\n",
      "obj = -814.707363, rho = -0.210829\n",
      "nSV = 909, nBSV = 896\n",
      "*\n",
      "optimization finished, #iter = 209\n",
      "obj = -279.481643, rho = 0.142011\n",
      "nSV = 326, nBSV = 318\n",
      "Total nSV = 326\n",
      "*\n",
      "optimization finished, #iter = 226\n",
      "obj = -300.217214, rho = -0.062227\n",
      "nSV = 344, nBSV = 335\n",
      "Total nSV = 344\n",
      "*\n",
      "optimization finished, #iter = 218\n",
      "obj = -278.322420, rho = 0.035744\n",
      "nSV = 322, nBSV = 313\n",
      "Total nSV = 322\n",
      "*\n",
      "optimization finished, #iter = 217\n",
      "obj = -279.938647, rho = -0.068915\n",
      "nSV = 322, nBSV = 314\n",
      "Total nSV = 322\n",
      "*\n",
      "optimization finished, #iter = 220\n",
      "obj = -280.775590, rho = 0.143540\n",
      "nSV = 325, nBSV = 317\n",
      "Total nSV = 325\n",
      "*\n",
      "optimization finished, #iter = 263\n",
      "obj = -345.444907, rho = -0.014041\n",
      "nSV = 393, nBSV = 385\n",
      "*\n",
      "optimization finished, #iter = 596\n",
      "obj = -808.372683, rho = 0.529659\n",
      "nSV = 913, nBSV = 902\n",
      "Total nSV = 913\n",
      "*\n",
      "optimization finished, #iter = 664\n",
      "obj = -796.047721, rho = 0.797036\n",
      "nSV = 903, nBSV = 890\n",
      "Total nSV = 903\n",
      "*\n",
      "optimization finished, #iter = 596\n",
      "obj = -799.071063, rho = 0.838157\n",
      "nSV = 903, nBSV = 892\n",
      "Total nSV = 903\n",
      "*\n",
      "optimization finished, #iter = 611\n",
      "obj = -807.920794, rho = 0.909712\n",
      "nSV = 913, nBSV = 899\n",
      "Total nSV = 913\n",
      "*\n",
      "optimization finished, #iter = 631\n",
      "obj = -794.963544, rho = 0.805850\n",
      "nSV = 902, nBSV = 890\n",
      "Total nSV = 902\n",
      "*\n",
      "optimization finished, #iter = 716\n",
      "obj = -976.588912, rho = -0.639328\n",
      "nSV = 1097, nBSV = 1084\n",
      "*\n",
      "optimization finished, #iter = 525\n",
      "obj = -694.998443, rho = -0.365176\n",
      "nSV = 749, nBSV = 736\n",
      "Total nSV = 749\n",
      "*\n",
      "optimization finished, #iter = 502\n",
      "obj = -691.055002, rho = -0.347344\n",
      "nSV = 745, nBSV = 733\n",
      "Total nSV = 745\n",
      "*\n",
      "optimization finished, #iter = 505\n",
      "obj = -668.098947, rho = -0.094008\n",
      "nSV = 726, nBSV = 715\n",
      "Total nSV = 726\n",
      "*\n",
      "optimization finished, #iter = 483\n",
      "obj = -670.936635, rho = -0.313520\n",
      "nSV = 729, nBSV = 716\n",
      "Total nSV = 729\n",
      "*\n",
      "optimization finished, #iter = 482\n",
      "obj = -655.443853, rho = 0.184217\n",
      "nSV = 712, nBSV = 702\n",
      "Total nSV = 712\n",
      "*\n",
      "optimization finished, #iter = 593\n",
      "obj = -833.337867, rho = 0.326926\n",
      "nSV = 896, nBSV = 887\n",
      "*\n",
      "optimization finished, #iter = 401\n",
      "obj = -496.319171, rho = -1.017513\n",
      "nSV = 556, nBSV = 544\n",
      "Total nSV = 556\n",
      "*\n",
      "optimization finished, #iter = 363\n",
      "obj = -493.450681, rho = -1.389993\n",
      "nSV = 550, nBSV = 543\n",
      "Total nSV = 550\n",
      "*\n",
      "optimization finished, #iter = 361\n",
      "obj = -481.327593, rho = -0.992433\n",
      "nSV = 543, nBSV = 532\n",
      "Total nSV = 543\n",
      "*\n",
      "optimization finished, #iter = 417\n",
      "obj = -492.483055, rho = -1.202376\n",
      "nSV = 555, nBSV = 543\n",
      "Total nSV = 555\n",
      "*\n",
      "optimization finished, #iter = 400\n",
      "obj = -483.317361, rho = -0.836515\n",
      "nSV = 542, nBSV = 528\n",
      "Total nSV = 542\n",
      "*\n",
      "optimization finished, #iter = 435\n",
      "obj = -598.755597, rho = 1.241718\n",
      "nSV = 665, nBSV = 655\n",
      "*\n",
      "optimization finished, #iter = 610\n",
      "obj = -734.986633, rho = 0.730311\n",
      "nSV = 825, nBSV = 810\n",
      "Total nSV = 825\n",
      "*\n",
      "optimization finished, #iter = 537\n",
      "obj = -707.652687, rho = 1.140989\n",
      "nSV = 796, nBSV = 781\n",
      "Total nSV = 796\n",
      "*\n",
      "optimization finished, #iter = 591\n",
      "obj = -717.045186, rho = 0.819133\n",
      "nSV = 807, nBSV = 792\n",
      "Total nSV = 807\n",
      "*\n",
      "optimization finished, #iter = 546\n",
      "obj = -750.494142, rho = 0.964832\n",
      "nSV = 838, nBSV = 825\n",
      "Total nSV = 838\n",
      "*\n",
      "optimization finished, #iter = 564\n",
      "obj = -725.779809, rho = 1.141367\n",
      "nSV = 816, nBSV = 803\n",
      "Total nSV = 816\n",
      "*\n",
      "optimization finished, #iter = 621\n",
      "obj = -888.387417, rho = -1.021146\n",
      "nSV = 986, nBSV = 976\n",
      "*\n",
      "optimization finished, #iter = 341\n",
      "obj = -428.589089, rho = 1.675353\n",
      "nSV = 530, nBSV = 522\n",
      "Total nSV = 530\n",
      "*\n",
      "optimization finished, #iter = 379\n",
      "obj = -451.101273, rho = 1.934258\n",
      "nSV = 552, nBSV = 540\n",
      "Total nSV = 552\n",
      "*\n",
      "optimization finished, #iter = 349\n",
      "obj = -455.400963, rho = 1.919493\n",
      "nSV = 554, nBSV = 543\n",
      "Total nSV = 554\n",
      "*\n",
      "optimization finished, #iter = 355\n",
      "obj = -446.570890, rho = 1.966051\n",
      "nSV = 546, nBSV = 538\n",
      "Total nSV = 546\n",
      "*\n",
      "optimization finished, #iter = 350\n",
      "obj = -449.551825, rho = 1.778115\n",
      "nSV = 547, nBSV = 538\n",
      "Total nSV = 547\n",
      "*\n",
      "optimization finished, #iter = 478\n",
      "obj = -533.684301, rho = -2.007665\n",
      "nSV = 646, nBSV = 634\n",
      "*\n",
      "optimization finished, #iter = 859\n",
      "obj = -1195.774601, rho = 0.652084\n",
      "nSV = 1329, nBSV = 1313\n",
      "Total nSV = 1329\n",
      "*\n",
      "optimization finished, #iter = 846\n",
      "obj = -1220.815988, rho = 0.351598\n",
      "nSV = 1350, nBSV = 1337\n",
      "Total nSV = 1350\n",
      "*\n",
      "optimization finished, #iter = 864\n",
      "obj = -1185.235880, rho = 0.629402\n",
      "nSV = 1318, nBSV = 1304\n",
      "Total nSV = 1318\n",
      "*\n",
      "optimization finished, #iter = 853\n",
      "obj = -1188.919608, rho = 0.547903\n",
      "nSV = 1319, nBSV = 1307\n",
      "Total nSV = 1319\n",
      "*\n",
      "optimization finished, #iter = 853\n",
      "obj = -1187.489772, rho = 0.653883\n",
      "nSV = 1306, nBSV = 1294\n",
      "Total nSV = 1306\n",
      "Line search fails in two-class probability estimates\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1059\n",
      "obj = -1463.243268, rho = -0.428823\n",
      "nSV = 1617, nBSV = 1604\n",
      "*\n",
      "optimization finished, #iter = 908\n",
      "obj = -1408.287449, rho = 0.573238\n",
      "nSV = 1498, nBSV = 1484\n",
      "Total nSV = 1498\n",
      "*\n",
      "optimization finished, #iter = 953\n",
      "obj = -1373.429295, rho = 0.418926\n",
      "nSV = 1462, nBSV = 1446\n",
      "Total nSV = 1462\n",
      "*\n",
      "optimization finished, #iter = 949\n",
      "obj = -1363.937797, rho = 0.675250\n",
      "nSV = 1452, nBSV = 1438\n",
      "Total nSV = 1452\n",
      "*\n",
      "optimization finished, #iter = 941\n",
      "obj = -1397.982221, rho = 0.354201\n",
      "nSV = 1483, nBSV = 1470\n",
      "Total nSV = 1483\n",
      "*\n",
      "optimization finished, #iter = 964\n",
      "obj = -1416.322625, rho = 0.568611\n",
      "nSV = 1501, nBSV = 1486\n",
      "Total nSV = 1501\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1195\n",
      "obj = -1720.145250, rho = -0.609608\n",
      "nSV = 1831, nBSV = 1813\n",
      "*\n",
      "optimization finished, #iter = 397\n",
      "obj = -526.693145, rho = 0.585664\n",
      "nSV = 588, nBSV = 575\n",
      "Total nSV = 588\n",
      "*\n",
      "optimization finished, #iter = 413\n",
      "obj = -525.819465, rho = 0.332271\n",
      "nSV = 585, nBSV = 573\n",
      "Total nSV = 585\n",
      "*\n",
      "optimization finished, #iter = 367\n",
      "obj = -509.270546, rho = 0.109283\n",
      "nSV = 571, nBSV = 561\n",
      "Total nSV = 571\n",
      "*\n",
      "optimization finished, #iter = 378\n",
      "obj = -519.012797, rho = 0.697541\n",
      "nSV = 576, nBSV = 565\n",
      "Total nSV = 576\n",
      "*\n",
      "optimization finished, #iter = 370\n",
      "obj = -516.448303, rho = -0.094913\n",
      "nSV = 574, nBSV = 563\n",
      "Total nSV = 574\n",
      "*\n",
      "optimization finished, #iter = 460\n",
      "obj = -636.960555, rho = -0.281530\n",
      "nSV = 706, nBSV = 696\n",
      "*\n",
      "optimization finished, #iter = 529\n",
      "obj = -703.383037, rho = -0.265754\n",
      "nSV = 777, nBSV = 764\n",
      "Total nSV = 777\n",
      "*\n",
      "optimization finished, #iter = 518\n",
      "obj = -694.464431, rho = -0.400270\n",
      "nSV = 768, nBSV = 756\n",
      "Total nSV = 768\n",
      "*\n",
      "optimization finished, #iter = 529\n",
      "obj = -660.258155, rho = -0.402594\n",
      "nSV = 738, nBSV = 726\n",
      "Total nSV = 738\n",
      "*\n",
      "optimization finished, #iter = 496\n",
      "obj = -676.745445, rho = -0.219431\n",
      "nSV = 752, nBSV = 741\n",
      "Total nSV = 752\n",
      "*\n",
      "optimization finished, #iter = 462\n",
      "obj = -675.118510, rho = -0.088180\n",
      "nSV = 747, nBSV = 739\n",
      "Total nSV = 747\n",
      "*\n",
      "optimization finished, #iter = 580\n",
      "obj = -835.407522, rho = 0.221647\n",
      "nSV = 918, nBSV = 908\n",
      "*\n",
      "optimization finished, #iter = 562\n",
      "obj = -800.697176, rho = -0.952110\n",
      "nSV = 869, nBSV = 859\n",
      "Total nSV = 869\n",
      "*\n",
      "optimization finished, #iter = 590\n",
      "obj = -807.997219, rho = -1.294996\n",
      "nSV = 880, nBSV = 868\n",
      "Total nSV = 880\n",
      "*\n",
      "optimization finished, #iter = 597\n",
      "obj = -838.974356, rho = -1.345748\n",
      "nSV = 908, nBSV = 900\n",
      "Total nSV = 908\n",
      "*\n",
      "optimization finished, #iter = 627\n",
      "obj = -819.594385, rho = -1.474150\n",
      "nSV = 892, nBSV = 880\n",
      "Total nSV = 892\n",
      "*\n",
      "optimization finished, #iter = 603\n",
      "obj = -814.577269, rho = -1.471206\n",
      "nSV = 888, nBSV = 879\n",
      "Total nSV = 888\n",
      "*\n",
      "optimization finished, #iter = 727\n",
      "obj = -1004.134171, rho = 1.448066\n",
      "nSV = 1089, nBSV = 1073\n",
      "*\n",
      "optimization finished, #iter = 664\n",
      "obj = -944.875252, rho = -0.086917\n",
      "nSV = 1058, nBSV = 1046\n",
      "Total nSV = 1058\n",
      "*\n",
      "optimization finished, #iter = 704\n",
      "obj = -946.609174, rho = 0.143785\n",
      "nSV = 1069, nBSV = 1051\n",
      "Total nSV = 1069\n",
      "*\n",
      "optimization finished, #iter = 687\n",
      "obj = -945.484375, rho = 0.137203\n",
      "nSV = 1064, nBSV = 1053\n",
      "Total nSV = 1064\n",
      "*\n",
      "optimization finished, #iter = 700\n",
      "obj = -932.750378, rho = 0.368735\n",
      "nSV = 1048, nBSV = 1034\n",
      "Total nSV = 1048\n",
      "*\n",
      "optimization finished, #iter = 714\n",
      "obj = -958.030726, rho = 0.003513\n",
      "nSV = 1073, nBSV = 1058\n",
      "Total nSV = 1073\n",
      "*\n",
      "optimization finished, #iter = 825\n",
      "obj = -1153.839393, rho = -0.094534\n",
      "nSV = 1287, nBSV = 1275\n",
      "*\n",
      "optimization finished, #iter = 847\n",
      "obj = -1225.736117, rho = 1.636879\n",
      "nSV = 1407, nBSV = 1398\n",
      "Total nSV = 1407\n",
      "*\n",
      "optimization finished, #iter = 892\n",
      "obj = -1237.373881, rho = 1.660310\n",
      "nSV = 1417, nBSV = 1404\n",
      "Total nSV = 1417\n",
      "*\n",
      "optimization finished, #iter = 854\n",
      "obj = -1232.563784, rho = 1.544912\n",
      "nSV = 1404, nBSV = 1392\n",
      "Total nSV = 1404\n",
      "*\n",
      "optimization finished, #iter = 871\n",
      "obj = -1226.475845, rho = 1.399756\n",
      "nSV = 1404, nBSV = 1390\n",
      "Total nSV = 1404\n",
      "*\n",
      "optimization finished, #iter = 868\n",
      "obj = -1240.657955, rho = 1.752230\n",
      "nSV = 1416, nBSV = 1405\n",
      "Total nSV = 1416\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1091\n",
      "obj = -1495.229407, rho = -1.795388\n",
      "nSV = 1703, nBSV = 1694\n",
      "*\n",
      "optimization finished, #iter = 886\n",
      "obj = -1230.739742, rho = 0.275501\n",
      "nSV = 1352, nBSV = 1343\n",
      "Total nSV = 1352\n",
      "*\n",
      "optimization finished, #iter = 900\n",
      "obj = -1248.387624, rho = 0.118039\n",
      "nSV = 1373, nBSV = 1361\n",
      "Total nSV = 1373\n",
      "*\n",
      "optimization finished, #iter = 863\n",
      "obj = -1239.071656, rho = 0.431101\n",
      "nSV = 1357, nBSV = 1346\n",
      "Total nSV = 1357\n",
      "*\n",
      "optimization finished, #iter = 902\n",
      "obj = -1222.639363, rho = 0.487116\n",
      "nSV = 1347, nBSV = 1332\n",
      "Total nSV = 1347\n",
      "*\n",
      "optimization finished, #iter = 869\n",
      "obj = -1203.177539, rho = 0.446269\n",
      "nSV = 1325, nBSV = 1313\n",
      "Total nSV = 1325\n",
      "*.*\n",
      "optimization finished, #iter = 1096\n",
      "obj = -1505.679512, rho = -0.345098\n",
      "nSV = 1656, nBSV = 1640\n",
      "*\n",
      "optimization finished, #iter = 675\n",
      "obj = -913.142216, rho = -0.987289\n",
      "nSV = 1007, nBSV = 993\n",
      "Total nSV = 1007\n",
      "*\n",
      "optimization finished, #iter = 675\n",
      "obj = -941.880661, rho = -0.651493\n",
      "nSV = 1037, nBSV = 1026\n",
      "Total nSV = 1037\n",
      "*\n",
      "optimization finished, #iter = 689\n",
      "obj = -941.809968, rho = -0.501660\n",
      "nSV = 1039, nBSV = 1026\n",
      "Total nSV = 1039\n",
      "*\n",
      "optimization finished, #iter = 621\n",
      "obj = -922.453889, rho = -0.730588\n",
      "nSV = 1017, nBSV = 1010\n",
      "Total nSV = 1017\n",
      "*\n",
      "optimization finished, #iter = 674\n",
      "obj = -940.605762, rho = -0.862924\n",
      "nSV = 1038, nBSV = 1026\n",
      "Total nSV = 1038\n",
      "*\n",
      "optimization finished, #iter = 784\n",
      "obj = -1142.683927, rho = 0.672064\n",
      "nSV = 1247, nBSV = 1237\n",
      "*\n",
      "optimization finished, #iter = 456\n",
      "obj = -544.071756, rho = -0.176196\n",
      "nSV = 640, nBSV = 628\n",
      "Total nSV = 640\n",
      "*\n",
      "optimization finished, #iter = 465\n",
      "obj = -552.033115, rho = -0.101496\n",
      "nSV = 648, nBSV = 636\n",
      "Total nSV = 648\n",
      "*\n",
      "optimization finished, #iter = 453\n",
      "obj = -560.511273, rho = -0.609682\n",
      "nSV = 657, nBSV = 644\n",
      "Total nSV = 657\n",
      "*\n",
      "optimization finished, #iter = 442\n",
      "obj = -535.413141, rho = -0.008853\n",
      "nSV = 631, nBSV = 620\n",
      "Total nSV = 631\n",
      "*\n",
      "optimization finished, #iter = 425\n",
      "obj = -533.578899, rho = -0.522805\n",
      "nSV = 629, nBSV = 621\n",
      "Total nSV = 629\n",
      "*\n",
      "optimization finished, #iter = 592\n",
      "obj = -658.611060, rho = 0.247137\n",
      "nSV = 770, nBSV = 756\n",
      "*\n",
      "optimization finished, #iter = 886\n",
      "obj = -1276.039758, rho = -2.360935\n",
      "nSV = 1384, nBSV = 1370\n",
      "Total nSV = 1384\n",
      "*\n",
      "optimization finished, #iter = 861\n",
      "obj = -1291.322698, rho = -2.130760\n",
      "nSV = 1390, nBSV = 1380\n",
      "Total nSV = 1390\n",
      "*\n",
      "optimization finished, #iter = 893\n",
      "obj = -1261.681619, rho = -2.002617\n",
      "nSV = 1365, nBSV = 1354\n",
      "Total nSV = 1365\n",
      "*\n",
      "optimization finished, #iter = 909\n",
      "obj = -1280.517679, rho = -1.999982\n",
      "nSV = 1387, nBSV = 1376\n",
      "Total nSV = 1387\n",
      "*\n",
      "optimization finished, #iter = 875\n",
      "obj = -1248.562862, rho = -2.103486\n",
      "nSV = 1347, nBSV = 1336\n",
      "Total nSV = 1347\n",
      "*.*\n",
      "optimization finished, #iter = 1053\n",
      "obj = -1565.402216, rho = 2.283029\n",
      "nSV = 1693, nBSV = 1677\n",
      "*\n",
      "optimization finished, #iter = 274\n",
      "obj = -353.682388, rho = 0.422252\n",
      "nSV = 409, nBSV = 397\n",
      "Total nSV = 409\n",
      "*\n",
      "optimization finished, #iter = 263\n",
      "obj = -341.054851, rho = 0.958824\n",
      "nSV = 395, nBSV = 387\n",
      "Total nSV = 395\n",
      "*\n",
      "optimization finished, #iter = 282\n",
      "obj = -340.479523, rho = 0.777040\n",
      "nSV = 396, nBSV = 383\n",
      "Total nSV = 396\n",
      "*\n",
      "optimization finished, #iter = 259\n",
      "obj = -346.889051, rho = 0.257842\n",
      "nSV = 401, nBSV = 391\n",
      "Total nSV = 401\n",
      "*\n",
      "optimization finished, #iter = 252\n",
      "obj = -351.227647, rho = 0.666157\n",
      "nSV = 404, nBSV = 399\n",
      "Total nSV = 404\n",
      "*\n",
      "optimization finished, #iter = 308\n",
      "obj = -421.560279, rho = -0.639157\n",
      "nSV = 481, nBSV = 471\n",
      "*\n",
      "optimization finished, #iter = 201\n",
      "obj = -247.761172, rho = 0.460835\n",
      "nSV = 307, nBSV = 298\n",
      "Total nSV = 307\n",
      "*\n",
      "optimization finished, #iter = 207\n",
      "obj = -260.626058, rho = 0.542610\n",
      "nSV = 321, nBSV = 314\n",
      "Total nSV = 321\n",
      "*\n",
      "optimization finished, #iter = 207\n",
      "obj = -249.170040, rho = 0.563039\n",
      "nSV = 309, nBSV = 302\n",
      "Total nSV = 309\n",
      "*\n",
      "optimization finished, #iter = 226\n",
      "obj = -255.683717, rho = 0.435524\n",
      "nSV = 317, nBSV = 306\n",
      "Total nSV = 317\n",
      "*\n",
      "optimization finished, #iter = 183\n",
      "obj = -248.204389, rho = 0.536352\n",
      "nSV = 304, nBSV = 299\n",
      "Total nSV = 304\n",
      "*\n",
      "optimization finished, #iter = 234\n",
      "obj = -301.564996, rho = -0.578948\n",
      "nSV = 366, nBSV = 359\n",
      "*\n",
      "optimization finished, #iter = 744\n",
      "obj = -1017.279382, rho = 0.884369\n",
      "nSV = 1146, nBSV = 1134\n",
      "Total nSV = 1146\n",
      "*\n",
      "optimization finished, #iter = 719\n",
      "obj = -1038.444337, rho = 0.678322\n",
      "nSV = 1174, nBSV = 1163\n",
      "Total nSV = 1174\n",
      "*\n",
      "optimization finished, #iter = 722\n",
      "obj = -1014.957663, rho = 0.908041\n",
      "nSV = 1148, nBSV = 1134\n",
      "Total nSV = 1148\n",
      "*\n",
      "optimization finished, #iter = 764\n",
      "obj = -1009.940919, rho = 1.069797\n",
      "nSV = 1142, nBSV = 1132\n",
      "Total nSV = 1142\n",
      "*\n",
      "optimization finished, #iter = 737\n",
      "obj = -1021.153562, rho = 0.735972\n",
      "nSV = 1148, nBSV = 1137\n",
      "Total nSV = 1148\n",
      "*\n",
      "optimization finished, #iter = 951\n",
      "obj = -1242.612795, rho = -0.717574\n",
      "nSV = 1401, nBSV = 1385\n",
      "*\n",
      "optimization finished, #iter = 919\n",
      "obj = -1307.187797, rho = -0.414818\n",
      "nSV = 1429, nBSV = 1415\n",
      "Total nSV = 1429\n",
      "*.*\n",
      "optimization finished, #iter = 1025\n",
      "obj = -1288.040096, rho = -0.211321\n",
      "nSV = 1406, nBSV = 1387\n",
      "Total nSV = 1406\n",
      "*\n",
      "optimization finished, #iter = 983\n",
      "obj = -1312.391878, rho = -0.266344\n",
      "nSV = 1435, nBSV = 1417\n",
      "Total nSV = 1435\n",
      "*\n",
      "optimization finished, #iter = 912\n",
      "obj = -1271.498820, rho = -0.433876\n",
      "nSV = 1392, nBSV = 1378\n",
      "Total nSV = 1392\n",
      "*\n",
      "optimization finished, #iter = 904\n",
      "obj = -1300.462160, rho = -0.281881\n",
      "nSV = 1413, nBSV = 1400\n",
      "Total nSV = 1413\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1110\n",
      "obj = -1590.135247, rho = 0.282618\n",
      "nSV = 1741, nBSV = 1722\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1110\n",
      "obj = -1394.311777, rho = 0.023940\n",
      "nSV = 1551, nBSV = 1531\n",
      "Total nSV = 1551\n",
      "*.*\n",
      "optimization finished, #iter = 1057\n",
      "obj = -1385.793274, rho = -0.363508\n",
      "nSV = 1546, nBSV = 1531\n",
      "Total nSV = 1546\n",
      "*.*\n",
      "optimization finished, #iter = 1052\n",
      "obj = -1417.223302, rho = 0.001485\n",
      "nSV = 1579, nBSV = 1564\n",
      "Total nSV = 1579\n",
      "*.*\n",
      "optimization finished, #iter = 1025\n",
      "obj = -1397.191776, rho = -0.117289\n",
      "nSV = 1555, nBSV = 1539\n",
      "Total nSV = 1555\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1049\n",
      "obj = -1428.644400, rho = -0.286629\n",
      "nSV = 1593, nBSV = 1578\n",
      "Total nSV = 1593\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1319\n",
      "obj = -1715.849162, rho = 0.258820\n",
      "nSV = 1918, nBSV = 1899\n",
      "*\n",
      "optimization finished, #iter = 310\n",
      "obj = -434.848837, rho = 1.545303\n",
      "nSV = 482, nBSV = 473\n",
      "Total nSV = 482\n",
      "*\n",
      "optimization finished, #iter = 319\n",
      "obj = -443.099938, rho = 2.015500\n",
      "nSV = 493, nBSV = 485\n",
      "Total nSV = 493\n",
      "*\n",
      "optimization finished, #iter = 358\n",
      "obj = -442.635029, rho = 1.983684\n",
      "nSV = 495, nBSV = 485\n",
      "Total nSV = 495\n",
      "*\n",
      "optimization finished, #iter = 323\n",
      "obj = -433.594495, rho = 1.783756\n",
      "nSV = 486, nBSV = 475\n",
      "Total nSV = 486\n",
      "*\n",
      "optimization finished, #iter = 324\n",
      "obj = -444.891161, rho = 2.055807\n",
      "nSV = 495, nBSV = 486\n",
      "Total nSV = 495\n",
      "*\n",
      "optimization finished, #iter = 388\n",
      "obj = -538.508415, rho = -2.116720\n",
      "nSV = 594, nBSV = 586\n",
      "*\n",
      "optimization finished, #iter = 256\n",
      "obj = -376.343307, rho = 1.758690\n",
      "nSV = 435, nBSV = 428\n",
      "Total nSV = 435\n",
      "*\n",
      "optimization finished, #iter = 269\n",
      "obj = -357.704375, rho = 0.976174\n",
      "nSV = 417, nBSV = 407\n",
      "Total nSV = 417\n",
      "*\n",
      "optimization finished, #iter = 273\n",
      "obj = -368.319636, rho = 1.769638\n",
      "nSV = 428, nBSV = 419\n",
      "Total nSV = 428\n",
      "*\n",
      "optimization finished, #iter = 263\n",
      "obj = -375.107030, rho = 1.556016\n",
      "nSV = 432, nBSV = 426\n",
      "Total nSV = 432\n",
      "*\n",
      "optimization finished, #iter = 319\n",
      "obj = -364.504755, rho = 1.780705\n",
      "nSV = 430, nBSV = 416\n",
      "Total nSV = 430\n",
      "*\n",
      "optimization finished, #iter = 403\n",
      "obj = -446.849679, rho = -1.818424\n",
      "nSV = 515, nBSV = 502\n",
      "*\n",
      "optimization finished, #iter = 647\n",
      "obj = -838.990476, rho = 1.977418\n",
      "nSV = 964, nBSV = 947\n",
      "Total nSV = 964\n",
      "*\n",
      "optimization finished, #iter = 613\n",
      "obj = -829.472847, rho = 1.857684\n",
      "nSV = 951, nBSV = 938\n",
      "Total nSV = 951\n",
      "*\n",
      "optimization finished, #iter = 623\n",
      "obj = -829.222756, rho = 1.921228\n",
      "nSV = 948, nBSV = 933\n",
      "Total nSV = 948\n",
      "*\n",
      "optimization finished, #iter = 608\n",
      "obj = -842.397275, rho = 1.815620\n",
      "nSV = 962, nBSV = 949\n",
      "Total nSV = 962\n",
      "*\n",
      "optimization finished, #iter = 590\n",
      "obj = -831.003028, rho = 1.839229\n",
      "nSV = 946, nBSV = 934\n",
      "Total nSV = 946\n",
      "*\n",
      "optimization finished, #iter = 763\n",
      "obj = -1012.993604, rho = -1.857632\n",
      "nSV = 1158, nBSV = 1144\n",
      "*\n",
      "optimization finished, #iter = 614\n",
      "obj = -895.403937, rho = 0.673833\n",
      "nSV = 971, nBSV = 958\n",
      "Total nSV = 971\n",
      "*\n",
      "optimization finished, #iter = 660\n",
      "obj = -897.138172, rho = 0.857856\n",
      "nSV = 974, nBSV = 958\n",
      "Total nSV = 974\n",
      "*\n",
      "optimization finished, #iter = 588\n",
      "obj = -884.415041, rho = 1.549122\n",
      "nSV = 961, nBSV = 950\n",
      "Total nSV = 961\n",
      "*\n",
      "optimization finished, #iter = 629\n",
      "obj = -880.833569, rho = 1.057431\n",
      "nSV = 958, nBSV = 945\n",
      "Total nSV = 958\n",
      "*\n",
      "optimization finished, #iter = 646\n",
      "obj = -885.761665, rho = 1.065871\n",
      "nSV = 963, nBSV = 948\n",
      "Total nSV = 963\n",
      "*\n",
      "optimization finished, #iter = 786\n",
      "obj = -1093.816606, rho = -1.158807\n",
      "nSV = 1181, nBSV = 1165\n",
      "*\n",
      "optimization finished, #iter = 766\n",
      "obj = -989.314372, rho = 0.786801\n",
      "nSV = 1177, nBSV = 1163\n",
      "Total nSV = 1177\n",
      "*\n",
      "optimization finished, #iter = 741\n",
      "obj = -970.955024, rho = 0.995479\n",
      "nSV = 1157, nBSV = 1143\n",
      "Total nSV = 1157\n",
      "*\n",
      "optimization finished, #iter = 735\n",
      "obj = -972.825916, rho = 1.170404\n",
      "nSV = 1150, nBSV = 1140\n",
      "Total nSV = 1150\n",
      "*\n",
      "optimization finished, #iter = 791\n",
      "obj = -1006.727797, rho = 0.680510\n",
      "nSV = 1190, nBSV = 1174\n",
      "Total nSV = 1190\n",
      "*\n",
      "optimization finished, #iter = 724\n",
      "obj = -986.582294, rho = 1.188049\n",
      "nSV = 1171, nBSV = 1154\n",
      "Total nSV = 1171\n",
      "*\n",
      "optimization finished, #iter = 917\n",
      "obj = -1184.963798, rho = -0.840322\n",
      "nSV = 1408, nBSV = 1390\n",
      "*\n",
      "optimization finished, #iter = 784\n",
      "obj = -1143.887640, rho = 1.665747\n",
      "nSV = 1264, nBSV = 1256\n",
      "Total nSV = 1264\n",
      "*\n",
      "optimization finished, #iter = 787\n",
      "obj = -1155.912659, rho = 1.523238\n",
      "nSV = 1271, nBSV = 1263\n",
      "Total nSV = 1271\n",
      "*\n",
      "optimization finished, #iter = 790\n",
      "obj = -1165.427925, rho = 1.741795\n",
      "nSV = 1285, nBSV = 1275\n",
      "Total nSV = 1285\n",
      "*\n",
      "optimization finished, #iter = 762\n",
      "obj = -1150.265839, rho = 1.182400\n",
      "nSV = 1265, nBSV = 1256\n",
      "Total nSV = 1265\n",
      "*\n",
      "optimization finished, #iter = 821\n",
      "obj = -1168.541574, rho = 1.428443\n",
      "nSV = 1289, nBSV = 1277\n",
      "Total nSV = 1289\n",
      "*\n",
      "optimization finished, #iter = 938\n",
      "obj = -1416.706690, rho = -1.541312\n",
      "nSV = 1555, nBSV = 1547\n",
      "*\n",
      "optimization finished, #iter = 507\n",
      "obj = -649.824058, rho = -0.464617\n",
      "nSV = 750, nBSV = 738\n",
      "Total nSV = 750\n",
      "*\n",
      "optimization finished, #iter = 460\n",
      "obj = -648.597307, rho = -0.820532\n",
      "nSV = 748, nBSV = 741\n",
      "Total nSV = 748\n",
      "*\n",
      "optimization finished, #iter = 482\n",
      "obj = -644.191057, rho = -0.514781\n",
      "nSV = 743, nBSV = 733\n",
      "Total nSV = 743\n",
      "*\n",
      "optimization finished, #iter = 482\n",
      "obj = -663.505024, rho = -0.810700\n",
      "nSV = 761, nBSV = 752\n",
      "Total nSV = 761\n",
      "*\n",
      "optimization finished, #iter = 522\n",
      "obj = -660.957425, rho = -0.489073\n",
      "nSV = 764, nBSV = 751\n",
      "Total nSV = 764\n",
      "*\n",
      "optimization finished, #iter = 672\n",
      "obj = -792.313602, rho = 0.845277\n",
      "nSV = 909, nBSV = 893\n",
      "*\n",
      "optimization finished, #iter = 351\n",
      "obj = -472.163158, rho = -1.177538\n",
      "nSV = 545, nBSV = 536\n",
      "Total nSV = 545\n",
      "*\n",
      "optimization finished, #iter = 400\n",
      "obj = -502.260690, rho = -0.823866\n",
      "nSV = 575, nBSV = 564\n",
      "Total nSV = 575\n",
      "*\n",
      "optimization finished, #iter = 403\n",
      "obj = -501.743197, rho = -0.879794\n",
      "nSV = 576, nBSV = 564\n",
      "Total nSV = 576\n",
      "*\n",
      "optimization finished, #iter = 393\n",
      "obj = -503.123532, rho = -0.596362\n",
      "nSV = 578, nBSV = 566\n",
      "Total nSV = 578\n",
      "*\n",
      "optimization finished, #iter = 386\n",
      "obj = -500.427078, rho = -0.955284\n",
      "nSV = 575, nBSV = 565\n",
      "Total nSV = 575\n",
      "*\n",
      "optimization finished, #iter = 463\n",
      "obj = -603.367971, rho = 0.830234\n",
      "nSV = 682, nBSV = 674\n",
      "*\n",
      "optimization finished, #iter = 235\n",
      "obj = -336.573554, rho = -0.595926\n",
      "nSV = 386, nBSV = 379\n",
      "Total nSV = 386\n",
      "*\n",
      "optimization finished, #iter = 217\n",
      "obj = -321.476909, rho = -1.081118\n",
      "nSV = 373, nBSV = 367\n",
      "Total nSV = 373\n",
      "*\n",
      "optimization finished, #iter = 232\n",
      "obj = -344.548569, rho = -0.406270\n",
      "nSV = 393, nBSV = 386\n",
      "Total nSV = 393\n",
      "*\n",
      "optimization finished, #iter = 292\n",
      "obj = -346.950734, rho = -0.816791\n",
      "nSV = 400, nBSV = 389\n",
      "Total nSV = 400\n",
      "*\n",
      "optimization finished, #iter = 266\n",
      "obj = -327.443612, rho = -0.921138\n",
      "nSV = 378, nBSV = 368\n",
      "Total nSV = 378\n",
      "*\n",
      "optimization finished, #iter = 318\n",
      "obj = -408.019102, rho = 0.856814\n",
      "nSV = 465, nBSV = 454\n",
      "*\n",
      "optimization finished, #iter = 474\n",
      "obj = -589.997211, rho = -0.645898\n",
      "nSV = 693, nBSV = 684\n",
      "Total nSV = 693\n",
      "*\n",
      "optimization finished, #iter = 443\n",
      "obj = -566.739876, rho = -0.641433\n",
      "nSV = 670, nBSV = 662\n",
      "Total nSV = 670\n",
      "*\n",
      "optimization finished, #iter = 445\n",
      "obj = -576.368449, rho = -0.172344\n",
      "nSV = 677, nBSV = 670\n",
      "Total nSV = 677\n",
      "*\n",
      "optimization finished, #iter = 478\n",
      "obj = -574.112357, rho = -0.836500\n",
      "nSV = 675, nBSV = 665\n",
      "Total nSV = 675\n",
      "*\n",
      "optimization finished, #iter = 480\n",
      "obj = -564.290313, rho = -0.833488\n",
      "nSV = 661, nBSV = 651\n",
      "Total nSV = 661\n",
      "*\n",
      "optimization finished, #iter = 518\n",
      "obj = -692.964352, rho = 0.758181\n",
      "nSV = 810, nBSV = 799\n",
      "*\n",
      "optimization finished, #iter = 326\n",
      "obj = -383.423843, rho = -1.504687\n",
      "nSV = 465, nBSV = 456\n",
      "Total nSV = 465\n",
      "*\n",
      "optimization finished, #iter = 337\n",
      "obj = -392.879538, rho = -1.723836\n",
      "nSV = 474, nBSV = 465\n",
      "Total nSV = 474\n",
      "*\n",
      "optimization finished, #iter = 333\n",
      "obj = -370.971140, rho = -1.511079\n",
      "nSV = 458, nBSV = 448\n",
      "Total nSV = 458\n",
      "*\n",
      "optimization finished, #iter = 314\n",
      "obj = -389.800933, rho = -1.460215\n",
      "nSV = 472, nBSV = 468\n",
      "Total nSV = 472\n",
      "*\n",
      "optimization finished, #iter = 341\n",
      "obj = -407.183602, rho = -1.624302\n",
      "nSV = 489, nBSV = 480\n",
      "Total nSV = 489\n",
      "*\n",
      "optimization finished, #iter = 365\n",
      "obj = -466.228589, rho = 1.864773\n",
      "nSV = 559, nBSV = 550\n",
      "*\n",
      "optimization finished, #iter = 180\n",
      "obj = -217.622724, rho = -0.825188\n",
      "nSV = 266, nBSV = 261\n",
      "Total nSV = 266\n",
      "*\n",
      "optimization finished, #iter = 173\n",
      "obj = -217.640218, rho = -0.584114\n",
      "nSV = 265, nBSV = 260\n",
      "Total nSV = 265\n",
      "*\n",
      "optimization finished, #iter = 195\n",
      "obj = -216.116730, rho = -0.724322\n",
      "nSV = 268, nBSV = 258\n",
      "Total nSV = 268\n",
      "*\n",
      "optimization finished, #iter = 228\n",
      "obj = -222.413738, rho = -1.020844\n",
      "nSV = 275, nBSV = 265\n",
      "Total nSV = 275\n",
      "*\n",
      "optimization finished, #iter = 230\n",
      "obj = -214.256660, rho = -0.914044\n",
      "nSV = 266, nBSV = 256\n",
      "Total nSV = 266\n",
      "*\n",
      "optimization finished, #iter = 200\n",
      "obj = -260.350240, rho = 0.993815\n",
      "nSV = 317, nBSV = 309\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1130\n",
      "obj = -1565.076935, rho = -0.807701\n",
      "nSV = 1786, nBSV = 1767\n",
      "Total nSV = 1786\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*.\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1136\n",
      "obj = -1596.205821, rho = -0.408915\n",
      "nSV = 1809, nBSV = 1794\n",
      "Total nSV = 1809\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1086\n",
      "obj = -1604.002624, rho = -0.082496\n",
      "nSV = 1824, nBSV = 1810\n",
      "Total nSV = 1824\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1108\n",
      "obj = -1587.339179, rho = -0.563140\n",
      "nSV = 1796, nBSV = 1782\n",
      "Total nSV = 1796\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1143\n",
      "obj = -1612.323278, rho = -0.213667\n",
      "nSV = 1825, nBSV = 1812\n",
      "Total nSV = 1825\n",
      ".\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 1373\n",
      "obj = -1938.204300, rho = 0.305299\n",
      "nSV = 2189, nBSV = 2175\n",
      "*\n",
      "optimization finished, #iter = 603\n",
      "obj = -766.280254, rho = -0.620234\n",
      "nSV = 864, nBSV = 853\n",
      "Total nSV = 864\n",
      "*\n",
      "optimization finished, #iter = 606\n",
      "obj = -772.893351, rho = -0.366332\n",
      "nSV = 870, nBSV = 857\n",
      "Total nSV = 870\n",
      "*\n",
      "optimization finished, #iter = 597\n",
      "obj = -762.972355, rho = -0.586103\n",
      "nSV = 859, nBSV = 846\n",
      "Total nSV = 859\n",
      "*\n",
      "optimization finished, #iter = 604\n",
      "obj = -755.512908, rho = -0.649734\n",
      "nSV = 850, nBSV = 838\n",
      "Total nSV = 850\n",
      "*\n",
      "optimization finished, #iter = 618\n",
      "obj = -762.919179, rho = -0.670479\n",
      "nSV = 866, nBSV = 853\n",
      "Total nSV = 866\n",
      "*\n",
      "optimization finished, #iter = 642\n",
      "obj = -931.562797, rho = 0.604323\n",
      "nSV = 1045, nBSV = 1035\n",
      "*\n",
      "optimization finished, #iter = 668\n",
      "obj = -804.671815, rho = 0.290643\n",
      "nSV = 935, nBSV = 918\n",
      "Total nSV = 935\n",
      "*\n",
      "optimization finished, #iter = 627\n",
      "obj = -802.330257, rho = 0.497385\n",
      "nSV = 934, nBSV = 917\n",
      "Total nSV = 934\n",
      "*\n",
      "optimization finished, #iter = 590\n",
      "obj = -764.731250, rho = 0.469255\n",
      "nSV = 883, nBSV = 873\n",
      "Total nSV = 883\n",
      "*\n",
      "optimization finished, #iter = 639\n",
      "obj = -792.026027, rho = 0.369281\n",
      "nSV = 910, nBSV = 897\n",
      "Total nSV = 910\n",
      "*\n",
      "optimization finished, #iter = 689\n",
      "obj = -810.824770, rho = 0.499082\n",
      "nSV = 940, nBSV = 924\n",
      "Total nSV = 940\n",
      "*\n",
      "optimization finished, #iter = 741\n",
      "obj = -963.036012, rho = -0.389368\n",
      "nSV = 1114, nBSV = 1100\n",
      "Total nSV = 12845\n",
      "Accuracy: 0.6107814045499506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       458\n",
      "           1       0.49      0.47      0.48       396\n",
      "           2       0.49      0.62      0.55       363\n",
      "           3       0.56      0.68      0.62       497\n",
      "           4       0.53      0.48      0.50       294\n",
      "           5       0.73      0.71      0.72       368\n",
      "           6       0.72      0.80      0.76       498\n",
      "           7       0.55      0.45      0.49       388\n",
      "           8       0.49      0.45      0.47       396\n",
      "           9       0.75      0.61      0.67       386\n",
      "\n",
      "    accuracy                           0.61      4044\n",
      "   macro avg       0.61      0.60      0.60      4044\n",
      "weighted avg       0.61      0.61      0.61      4044\n",
      "\n",
      "\n",
      "k-Nearest Neighbors (k-NN):\n",
      "Accuracy: 0.5452522255192879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       458\n",
      "           1       0.41      0.42      0.41       396\n",
      "           2       0.45      0.59      0.51       363\n",
      "           3       0.47      0.61      0.53       497\n",
      "           4       0.48      0.37      0.42       294\n",
      "           5       0.75      0.69      0.72       368\n",
      "           6       0.73      0.78      0.75       498\n",
      "           7       0.42      0.32      0.36       388\n",
      "           8       0.36      0.28      0.31       396\n",
      "           9       0.67      0.54      0.60       386\n",
      "\n",
      "    accuracy                           0.55      4044\n",
      "   macro avg       0.54      0.53      0.53      4044\n",
      "weighted avg       0.54      0.55      0.54      4044\n",
      "\n",
      "\n",
      "Naïve Bayes Classifier:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(report)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNaïve Bayes Classifier:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m report, acc \u001b[38;5;241m=\u001b[39m \u001b[43mnaive_bayes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, acc)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(report)\n",
      "File \u001b[0;32m~/#/Major02/models.py:83\u001b[0m, in \u001b[0;36mnaive_bayes\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     79\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     81\u001b[0m model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[0;32m---> 83\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classification_report(y_test, y_pred), accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/naive_bayes.py:762\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    760\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[0;32m--> 762\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/naive_bayes.py:889\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[1;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultinomialNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/utils/validation.py:1827\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m   1824\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1827\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhom\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)."
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "report, acc = logistic_regression(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "report, acc = decision_tree(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "report, acc = random_forest(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nSupport Vector Machine (SVM):\")\n",
    "report, acc = support_vector_machine(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nk-Nearest Neighbors (k-NN):\")\n",
    "report, acc = knn(X, y, k=5)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nNaïve Bayes Classifier:\")\n",
    "report, acc = naive_bayes(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nGradient Boosting (XGBoost):\")\n",
    "report, acc = xgboost_classifier(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nMulti-Layer Perceptron (MLP - Neural Network):\")\n",
    "report, acc = mlp_classifier(X, y)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating BERT Embeddings on GPU: 100%|██████████| 20219/20219 [02:22<00:00, 141.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT + Logistic Regression Accuracy: 0.8029\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pre-trained BERT tokenizer & model on GPU\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)  # Move model to GPU\n",
    "\n",
    "# Function to get BERT embeddings using GPU\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  # Move result back to CPU for NumPy\n",
    "\n",
    "# Convert text to BERT embeddings with progress bar\n",
    "X_bert = np.array([get_bert_embedding(text) for text in tqdm(df['text'], desc=\"Generating BERT Embeddings on GPU\")])\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(X_bert, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_bert, y_train_bert)\n",
    "\n",
    "# Predict & Evaluate\n",
    "y_pred_bert = lr_model.predict(X_test_bert)\n",
    "bert_acc = accuracy_score(y_test_bert, y_pred_bert)\n",
    "print(f\"BERT + Logistic Regression Accuracy: {bert_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['topic', 'question', 'excerpt'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_bert']=X_bert.tolist()\n",
    "df['x_w2v']=X_w2v.tolist()\n",
    "df['x_tfidf']=X.toarray().tolist()\n",
    "df['question']=TRAIN['question']\n",
    "df['excerpt']=TRAIN['excerpt']\n",
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Move result back to CPU for NumPy\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Convert text to BERT embeddings with progress bar\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m X_bert \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_bert_embedding(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating BERT Embeddings on GPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Move result back to CPU for NumPy\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Convert text to BERT embeddings with progress bar\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m X_bert \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_bert_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating BERT Embeddings on GPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mget_bert_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     16\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 18\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/transformers/pytorch_utils.py:261\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Check if GPU is available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Load pre-trained BERT tokenizer & model on GPU\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)  # Move model to GPU\n",
    "\n",
    "# # Function to get BERT embeddings using GPU\n",
    "# def get_bert_embedding(text):\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = bert_model(**inputs)\n",
    "#     return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  # Move result back to CPU for NumPy\n",
    "\n",
    "# # Convert text to BERT embeddings with progress bar\n",
    "# X_bert = np.array([get_bert_embedding(text) for text in tqdm(df['text'], desc=\"Generating BERT Embeddings on GPU\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Embeddings Method\n",
    "\n",
    "In this section, we will use GloVe (Global Vectors for Word Representation) embeddings to convert text data into numerical vectors. GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\n",
    "\n",
    "We will follow these steps:\n",
    "1. Load pre-trained GloVe embeddings.\n",
    "2. Create a function to convert text into GloVe embeddings.\n",
    "3. Apply the function to our dataset to obtain GloVe embeddings for each text.\n",
    "4. Train and evaluate machine learning models using these embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load Pretrained GloVe Model\n",
    "glove_model = api.load(\"glove-wiki-gigaword-300\")  \n",
    "\n",
    "# Convert a sentence to a vector by averaging word embeddings\n",
    "def get_sentence_embedding(sentence, model, dim=300):\n",
    "    words = sentence.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(dim)\n",
    "\n",
    "text_samples = [\"GloVe embeddings capture word semantics\"]\n",
    "embeddings = np.array([get_sentence_embedding(text, glove_model) for text in text_samples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating GloVe Embeddings: 100%|██████████| 20219/20219 [00:00<00:00, 26234.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20219, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Generate GloVe embeddings for the entire dataset with a progress bar\n",
    "df['glove_embeddings'] = df['text'].apply(lambda x: get_sentence_embedding(x, glove_model))\n",
    "\n",
    "# Convert the list of embeddings to a numpy array\n",
    "X_glove = np.array([get_sentence_embedding(text, glove_model) for text in tqdm(df['text'], desc=\"Generating GloVe Embeddings\")])\n",
    "\n",
    "# Check the shape of the generated embeddings\n",
    "print(X_glove.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.115741186, -0.20021904, 0.12441649, -0.324...\n",
       "1        [-0.0010313676, -0.06625991, 0.31336138, -0.32...\n",
       "2        [-0.08451371, -0.041777406, -0.17886283, -0.18...\n",
       "3        [-0.1282833, 0.19806932, 0.16693015, -0.017683...\n",
       "4        [-0.073781654, 0.05777748, -0.10044446, -0.301...\n",
       "                               ...                        \n",
       "20214    [-0.36480942, 0.14811745, 0.0026721125, -0.169...\n",
       "20215    [-0.12177454, 0.06218006, -0.05326008, -0.0159...\n",
       "20216    [-0.02713412, 0.04559438, 0.006360337, -0.1446...\n",
       "20217    [-0.29473746, 0.2867133, -0.12950301, -0.03180...\n",
       "20218    [-0.3100589, 0.15244281, 0.0920101, -0.0856748...\n",
       "Name: glove_embeddings, Length: 20219, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['glove_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['glove_embeddings']\n",
    "y = label_encoding(df['topic']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type numpy.ndarray which has no callable exp method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'exp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msigmoid\u001b[39m(x):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mx))\n\u001b[0;32m----> 6\u001b[0m X_sigmoid \u001b[38;5;241m=\u001b[39m \u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m, in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msigmoid\u001b[39m(x):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/pandas/core/generic.py:2171\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2167\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   2168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[1;32m   2169\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   2170\u001b[0m ):\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marraylike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/pandas/core/arraylike.py:399\u001b[0m, in \u001b[0;36marray_ufunc\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# ufunc(series, ...)\u001b[39;00m\n\u001b[1;32m    398\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(extract_array(x, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[0;32m--> 399\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# ufunc(dataframe)\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__call__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# for np.<ufunc>(..) calls\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;66;03m# kwargs cannot necessarily be handled block-by-block, so only\u001b[39;00m\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# take this path if there are no kwargs\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type numpy.ndarray which has no callable exp method"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "X_sigmoid = sigmoid(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# X_sigmoid = sigmoid(X)\n",
    "\n",
    "X_s = X.apply(lambda emb: sigmoid(np.array(emb)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.471097  0.450112  0.531064  0.419600  0.529166  0.501688  0.539391   \n",
      "1  0.499742  0.483441  0.577706  0.419251  0.488925  0.483124  0.525759   \n",
      "2  0.478884  0.489557  0.455403  0.454474  0.504673  0.511277  0.525448   \n",
      "3  0.467973  0.549356  0.541636  0.495579  0.533500  0.510909  0.493776   \n",
      "4  0.481563  0.514440  0.474910  0.425199  0.494169  0.486540  0.507572   \n",
      "\n",
      "        7         8         9    ...       290       291       292       293  \\\n",
      "0  0.504431  0.471951  0.210885  ...  0.484047  0.508446  0.468081  0.511043   \n",
      "1  0.498380  0.512296  0.295908  ...  0.508435  0.516001  0.475152  0.510036   \n",
      "2  0.496180  0.487645  0.263449  ...  0.493034  0.459211  0.474147  0.547312   \n",
      "3  0.516288  0.510662  0.222204  ...  0.497405  0.476240  0.471470  0.508767   \n",
      "4  0.513841  0.517520  0.228781  ...  0.491363  0.455957  0.501189  0.502150   \n",
      "\n",
      "        294       295       296       297       298       299  \n",
      "0  0.517152  0.517413  0.513905  0.434282  0.511256  0.497362  \n",
      "1  0.555465  0.471034  0.474005  0.468187  0.533218  0.529335  \n",
      "2  0.483106  0.559323  0.500045  0.493877  0.498814  0.523413  \n",
      "3  0.494089  0.537543  0.479127  0.483230  0.505795  0.493756  \n",
      "4  0.512769  0.518822  0.506260  0.456117  0.517466  0.527945  \n",
      "\n",
      "[5 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Apply sigmoid function element-wise to each embedding\n",
    "X_sigmoid = X.apply(lambda emb: np.array([sigmoid(val) for val in emb]))\n",
    "\n",
    "# If you need it as a DataFrame:\n",
    "X_sigmoid_df = pd.DataFrame(X_sigmoid.tolist())\n",
    "\n",
    "print(X_sigmoid_df.head())  # Display first few rows\n",
    "\n",
    "df['glove_sigmoid']=X_sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['glove_sigmoid']\n",
    "y = label_encoding(df['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multi-Layer Perceptron (MLP - Neural Network):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 37\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(\"Logistic Regression:\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# report, acc = logistic_regression(X, y)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(\"Accuracy:\", acc)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# print(\"Accuracy:\", acc)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# print(report)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMulti-Layer Perceptron (MLP - Neural Network):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m report, acc \u001b[38;5;241m=\u001b[39m \u001b[43mmlp_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, acc)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(report)\n",
      "File \u001b[0;32m~/#/Major02/models.py:118\u001b[0m, in \u001b[0;36mmlp_classifier\u001b[0;34m(X, y, epochs, lr)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmlp_classifier\u001b[39m(X, y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Normalize data without centering (for sparse matrices)\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m StandardScaler(with_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Fix applied here\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# Convert to PyTorch tensors\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    904\u001b[0m             (\n\u001b[1;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    914\u001b[0m         )\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:894\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:930\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \n\u001b[1;32m    900\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    929\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 930\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/utils/validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/utils/_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/pandas/core/series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# print(\"Logistic Regression:\")\n",
    "# report, acc = logistic_regression(X, y)\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(report)\n",
    "\n",
    "# print(\"\\nDecision Tree Classifier:\")\n",
    "# report, acc = decision_tree(X, y)\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(report)\n",
    "\n",
    "# print(\"\\nRandom Forest Classifier:\")\n",
    "# report, acc = random_forest(X, y)\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(report)\n",
    "\n",
    "# print(\"\\nSupport Vector Machine (SVM):\")\n",
    "# report, acc = support_vector_machine(X, y)\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(report)\n",
    "\n",
    "# print(\"\\nk-Nearest Neighbors (k-NN):\")\n",
    "# report, acc = knn(X, y, k=5)\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(report)\n",
    "\n",
    "# print(\"\\nNaïve Bayes Classifier:\")\n",
    "# report, acc = naive_bayes(X, y)\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(report)\n",
    "\n",
    "# print(\"\\nGradient Boosting (XGBoost):\")\n",
    "# report, acc = xgboost_classifier(X, y)\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(report)\n",
    "\n",
    "print(\"\\nMulti-Layer Perceptron (MLP - Neural Network):\")\n",
    "report, acc = mlp_classifier(X, y)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Requirement already satisfied: setuptools in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from tensorflow) (65.5.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: packaging in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting tensorboard~=2.19.0\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1\n",
      "  Using cached ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (395 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 protobuf-5.29.3 rich-13.9.4 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wheel-0.45.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20219, 300)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16175, 300) (4044, 300) (16175, 10) (4044, 10)\n",
      "Epoch [1/100], Loss: 2.2988\n",
      "Epoch [2/100], Loss: 2.2972\n",
      "Epoch [3/100], Loss: 2.3108\n",
      "Epoch [4/100], Loss: 2.3176\n",
      "Epoch [5/100], Loss: 2.2910\n",
      "Epoch [6/100], Loss: 2.2063\n",
      "Epoch [7/100], Loss: 2.1915\n",
      "Epoch [8/100], Loss: 2.1855\n",
      "Epoch [9/100], Loss: 2.1844\n",
      "Epoch [10/100], Loss: 2.1815\n",
      "Epoch [11/100], Loss: 2.1742\n",
      "Epoch [12/100], Loss: 2.1727\n",
      "Epoch [13/100], Loss: 2.1802\n",
      "Epoch [14/100], Loss: 2.1745\n",
      "Epoch [15/100], Loss: 2.1711\n",
      "Epoch [16/100], Loss: 2.1736\n",
      "Epoch [17/100], Loss: 2.1669\n",
      "Epoch [18/100], Loss: 2.1763\n",
      "Epoch [19/100], Loss: 2.1600\n",
      "Epoch [20/100], Loss: 2.1624\n",
      "Epoch [21/100], Loss: 2.1802\n",
      "Epoch [22/100], Loss: 2.1658\n",
      "Epoch [23/100], Loss: 2.1810\n",
      "Epoch [24/100], Loss: 2.1584\n",
      "Epoch [25/100], Loss: 2.1622\n",
      "Epoch [26/100], Loss: 2.1523\n",
      "Epoch [27/100], Loss: 2.1576\n",
      "Epoch [28/100], Loss: 2.1665\n",
      "Epoch [29/100], Loss: 2.1527\n",
      "Epoch [30/100], Loss: 2.1565\n",
      "Epoch [31/100], Loss: 2.1611\n",
      "Epoch [32/100], Loss: 2.1486\n",
      "Epoch [33/100], Loss: 2.1582\n",
      "Epoch [34/100], Loss: 2.1855\n",
      "Epoch [35/100], Loss: 2.1679\n",
      "Epoch [36/100], Loss: 2.1514\n",
      "Epoch [37/100], Loss: 2.1492\n",
      "Epoch [38/100], Loss: 2.1557\n",
      "Epoch [39/100], Loss: 2.1563\n",
      "Epoch [40/100], Loss: 2.1463\n",
      "Epoch [41/100], Loss: 2.1550\n",
      "Epoch [42/100], Loss: 2.1489\n",
      "Epoch [43/100], Loss: 2.1419\n",
      "Epoch [44/100], Loss: 2.1455\n",
      "Epoch [45/100], Loss: 2.1416\n",
      "Epoch [46/100], Loss: 2.1431\n",
      "Epoch [47/100], Loss: 2.1468\n",
      "Epoch [48/100], Loss: 2.1395\n",
      "Epoch [49/100], Loss: 2.1423\n",
      "Epoch [50/100], Loss: 2.1460\n",
      "Epoch [51/100], Loss: 2.1425\n",
      "Epoch [52/100], Loss: 2.1399\n",
      "Epoch [53/100], Loss: 2.1387\n",
      "Epoch [54/100], Loss: 2.1471\n",
      "Epoch [55/100], Loss: 2.1539\n",
      "Epoch [56/100], Loss: 2.1409\n",
      "Epoch [57/100], Loss: 2.1416\n",
      "Epoch [58/100], Loss: 2.1374\n",
      "Epoch [59/100], Loss: 2.1391\n",
      "Epoch [60/100], Loss: 2.1367\n",
      "Epoch [61/100], Loss: 2.1439\n",
      "Epoch [62/100], Loss: 2.1326\n",
      "Epoch [63/100], Loss: 2.1446\n",
      "Epoch [64/100], Loss: 2.1549\n",
      "Epoch [65/100], Loss: 2.1417\n",
      "Epoch [66/100], Loss: 2.1525\n",
      "Epoch [67/100], Loss: 2.1434\n",
      "Epoch [68/100], Loss: 2.1409\n",
      "Epoch [69/100], Loss: 2.1429\n",
      "Epoch [70/100], Loss: 2.1439\n",
      "Epoch [71/100], Loss: 2.1426\n",
      "Epoch [72/100], Loss: 2.1729\n",
      "Epoch [73/100], Loss: 2.1379\n",
      "Epoch [74/100], Loss: 2.1332\n",
      "Epoch [75/100], Loss: 2.1319\n",
      "Epoch [76/100], Loss: 2.1334\n",
      "Epoch [77/100], Loss: 2.1354\n",
      "Epoch [78/100], Loss: 2.1512\n",
      "Epoch [79/100], Loss: 2.1431\n",
      "Epoch [80/100], Loss: 2.1457\n",
      "Epoch [81/100], Loss: 2.1301\n",
      "Epoch [82/100], Loss: 2.1337\n",
      "Epoch [83/100], Loss: 2.1342\n",
      "Epoch [84/100], Loss: 2.1313\n",
      "Epoch [85/100], Loss: 2.1345\n",
      "Epoch [86/100], Loss: 2.1347\n",
      "Epoch [87/100], Loss: 2.1343\n",
      "Epoch [88/100], Loss: 2.1290\n",
      "Epoch [89/100], Loss: 2.1390\n",
      "Epoch [90/100], Loss: 2.1294\n",
      "Epoch [91/100], Loss: 2.1265\n",
      "Epoch [92/100], Loss: 2.1326\n",
      "Epoch [93/100], Loss: 2.1374\n",
      "Epoch [94/100], Loss: 2.1328\n",
      "Epoch [95/100], Loss: 2.1300\n",
      "Epoch [96/100], Loss: 2.1366\n",
      "Epoch [97/100], Loss: 2.1238\n",
      "Epoch [98/100], Loss: 2.1348\n",
      "Epoch [99/100], Loss: 2.1298\n",
      "Epoch [100/100], Loss: 2.1264\n",
      "\n",
      "Test Accuracy: 0.3205\n",
      "\n",
      "Predicted Labels: [0, 3, 5, 9, 6]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Convert data to NumPy arrays (if not already)\n",
    "X = np.array(X)  # Ensure X is a NumPy array\n",
    "y = np.array(y)  # Convert labels to NumPy array\n",
    "\n",
    "# Encode labels to integers (0-9)\n",
    "unique_labels = np.unique(y)\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_encoded = np.array([label_map[label] for label in y])\n",
    "\n",
    "# One-hot encode labels\n",
    "y_one_hot = np.eye(10)[y_encoded]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create DataLoader for efficient training\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the Neural Network Model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.softmax(self.fc5(x))\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = NeuralNet(input_size=X.shape[1], num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        _, labels = torch.max(batch_y, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predict on new data\n",
    "sample_X = X_test_tensor[:5]\n",
    "model.eval()\n",
    "predictions = model(sample_X)\n",
    "predicted_classes = torch.argmax(predictions, dim=1).cpu().numpy()\n",
    "predicted_labels = [unique_labels[idx] for idx in predicted_classes]\n",
    "print(\"\\nPredicted Labels:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-18 22:45:59.369565: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-18 22:45:59.377294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742318159.387742   95942 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742318159.392140   95942 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742318159.400755   95942 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742318159.400773   95942 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742318159.400774   95942 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742318159.400775   95942 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-18 22:45:59.403564: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Processing: 100%|██████████| 1264/1264 [00:40<00:00, 31.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "\n",
    "# Load ALBERT tokenizer and model\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "model = AlbertModel.from_pretrained(\"albert-base-v2\")\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load your dataset (Ensure df['text'] contains the text data)\n",
    "# df = pd.read_csv(\"your_dataset.csv\")  # Replace with your dataset file\n",
    "texts = df[\"text\"].tolist()\n",
    "\n",
    "# Function to generate embeddings\n",
    "def get_albert_embeddings(texts, batch_size=16):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    embeddings_list = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing\"):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        \n",
    "        # Tokenize the batch\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}  # Move to GPU/CPU\n",
    "        \n",
    "        # Get embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Extract [CLS] token representation (sentence embedding)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings_list.append(cls_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings_list)  # Stack all embeddings\n",
    "\n",
    "# Generate embeddings for all texts\n",
    "embeddings = get_albert_embeddings(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embeddings\n",
    "y = label_encoding(df['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.755192878338279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75       458\n",
      "           1       0.63      0.59      0.61       396\n",
      "           2       0.76      0.77      0.76       363\n",
      "           3       0.78      0.76      0.77       497\n",
      "           4       0.71      0.69      0.70       294\n",
      "           5       0.84      0.88      0.86       368\n",
      "           6       0.94      0.95      0.95       498\n",
      "           7       0.71      0.71      0.71       388\n",
      "           8       0.55      0.57      0.56       396\n",
      "           9       0.82      0.84      0.83       386\n",
      "\n",
      "    accuracy                           0.76      4044\n",
      "   macro avg       0.75      0.75      0.75      4044\n",
      "weighted avg       0.75      0.76      0.75      4044\n",
      "\n",
      "\n",
      "Decision Tree Classifier:\n",
      "Accuracy: 0.3508902077151335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.31      0.31       458\n",
      "           1       0.23      0.24      0.23       396\n",
      "           2       0.28      0.31      0.30       363\n",
      "           3       0.33      0.34      0.33       497\n",
      "           4       0.35      0.29      0.31       294\n",
      "           5       0.44      0.45      0.44       368\n",
      "           6       0.75      0.71      0.73       498\n",
      "           7       0.21      0.22      0.21       388\n",
      "           8       0.22      0.22      0.22       396\n",
      "           9       0.35      0.33      0.34       386\n",
      "\n",
      "    accuracy                           0.35      4044\n",
      "   macro avg       0.35      0.34      0.34      4044\n",
      "weighted avg       0.36      0.35      0.35      4044\n",
      "\n",
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 0.5558852621167161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.61      0.56       458\n",
      "           1       0.39      0.28      0.32       396\n",
      "           2       0.51      0.59      0.55       363\n",
      "           3       0.47      0.58      0.52       497\n",
      "           4       0.69      0.40      0.51       294\n",
      "           5       0.62      0.71      0.66       368\n",
      "           6       0.81      0.90      0.85       498\n",
      "           7       0.47      0.38      0.42       388\n",
      "           8       0.47      0.32      0.38       396\n",
      "           9       0.55      0.66      0.60       386\n",
      "\n",
      "    accuracy                           0.56      4044\n",
      "   macro avg       0.55      0.54      0.54      4044\n",
      "weighted avg       0.55      0.56      0.55      4044\n",
      "\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "Accuracy: 0.7101879327398615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       458\n",
      "           1       0.59      0.51      0.55       396\n",
      "           2       0.70      0.73      0.72       363\n",
      "           3       0.68      0.71      0.70       497\n",
      "           4       0.71      0.65      0.68       294\n",
      "           5       0.82      0.83      0.83       368\n",
      "           6       0.95      0.93      0.94       498\n",
      "           7       0.64      0.64      0.64       388\n",
      "           8       0.52      0.57      0.55       396\n",
      "           9       0.73      0.78      0.75       386\n",
      "\n",
      "    accuracy                           0.71      4044\n",
      "   macro avg       0.71      0.70      0.70      4044\n",
      "weighted avg       0.71      0.71      0.71      4044\n",
      "\n",
      "\n",
      "k-Nearest Neighbors (k-NN):\n",
      "Accuracy: 0.4394164193867458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.47      0.39       458\n",
      "           1       0.27      0.26      0.26       396\n",
      "           2       0.37      0.55      0.44       363\n",
      "           3       0.36      0.47      0.41       497\n",
      "           4       0.51      0.39      0.44       294\n",
      "           5       0.61      0.43      0.51       368\n",
      "           6       0.91      0.78      0.84       498\n",
      "           7       0.35      0.23      0.28       388\n",
      "           8       0.27      0.25      0.26       396\n",
      "           9       0.59      0.45      0.51       386\n",
      "\n",
      "    accuracy                           0.44      4044\n",
      "   macro avg       0.46      0.43      0.43      4044\n",
      "weighted avg       0.46      0.44      0.44      4044\n",
      "\n",
      "\n",
      "Gradient Boosting (XGBoost):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darth/.pyenv/versions/3.10.12/envs/major02/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:00:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6923837784371909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67       458\n",
      "           1       0.58      0.49      0.53       396\n",
      "           2       0.69      0.69      0.69       363\n",
      "           3       0.66      0.71      0.68       497\n",
      "           4       0.69      0.61      0.65       294\n",
      "           5       0.78      0.84      0.81       368\n",
      "           6       0.94      0.92      0.93       498\n",
      "           7       0.62      0.61      0.62       388\n",
      "           8       0.51      0.54      0.53       396\n",
      "           9       0.74      0.75      0.74       386\n",
      "\n",
      "    accuracy                           0.69      4044\n",
      "   macro avg       0.69      0.69      0.69      4044\n",
      "weighted avg       0.69      0.69      0.69      4044\n",
      "\n",
      "Accuracy: 0.6923837784371909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67       458\n",
      "           1       0.58      0.49      0.53       396\n",
      "           2       0.69      0.69      0.69       363\n",
      "           3       0.66      0.71      0.68       497\n",
      "           4       0.69      0.61      0.65       294\n",
      "           5       0.78      0.84      0.81       368\n",
      "           6       0.94      0.92      0.93       498\n",
      "           7       0.62      0.61      0.62       388\n",
      "           8       0.51      0.54      0.53       396\n",
      "           9       0.74      0.75      0.74       386\n",
      "\n",
      "    accuracy                           0.69      4044\n",
      "   macro avg       0.69      0.69      0.69      4044\n",
      "weighted avg       0.69      0.69      0.69      4044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "report, acc = logistic_regression(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "report, acc = decision_tree(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "report, acc = random_forest(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nSupport Vector Machine (SVM):\")\n",
    "report, acc = support_vector_machine(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nk-Nearest Neighbors (k-NN):\")\n",
    "report, acc = knn(X, y, k=5)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "# print(\"\\nNaïve Bayes Classifier:\")\n",
    "# report, acc = naive_bayes(X, y)\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(report)\n",
    "\n",
    "print(\"\\nGradient Boosting (XGBoost):\")\n",
    "report, acc = xgboost_classifier(X, y)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)\n",
    "\n",
    "# print(\"\\nMulti-Layer Perceptron (MLP - Neural Network):\")\n",
    "# report, acc = mlp_classifier(X, y)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "major02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
